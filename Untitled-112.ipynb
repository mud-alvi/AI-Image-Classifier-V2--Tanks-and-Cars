{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9075ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now working in: C:\\Users\\Mudassar\\Desktop\\Z_Image\n",
      "Name and Versions of libraries\n",
      "PyTorch version: 2.8.0+cu129\n",
      "Torchvision version: 0.23.0+cu129\n",
      "Numpy version: 2.1.2\n",
      "Matplotlib version: 3.10.6\n",
      "Pandas Version: 2.3.2\n",
      "Scikit-image version: 0.25.2\n",
      "Device: cuda\n",
      "GPU device name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch as th \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os \n",
    "os.chdir(r\"C:\\Users\\Mudassar\\Desktop\\Z_Image\")\n",
    "print(\"Now working in:\", os.getcwd())\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "import skimage as ski\n",
    "from skimage import io, color\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from torchsummary import summary \n",
    "\n",
    "print (\"Name and Versions of libraries\")\n",
    "print (\"PyTorch version:\", th.__version__)\n",
    "print (\"Torchvision version:\", tv.__version__)\n",
    "print (\"Numpy version:\", np.__version__)\n",
    "print (\"Matplotlib version:\", matplotlib.__version__)\n",
    "print(\"Pandas Version:\", pd.__version__)\n",
    "print (\"Scikit-image version:\", ski.__version__)\n",
    "\n",
    "print (\"Device:\", th.device(\"cuda\" if th.cuda.is_available() else \"cpu\"))\n",
    "if th.cuda.is_available():\n",
    "    print(f\"GPU device name: {th.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"GPU device not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753bde91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Creating a dataset ---\n",
    "\n",
    "\n",
    "\n",
    "class CustomDatasetCarsANDTanks(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "        # -- filtering out rows with missing files\n",
    "        for _, row in self.data.iterrows():\n",
    "            img_path = os.path.join(self.root_dir, row.iloc[0])\n",
    "            if not os.path.isfile(img_path):\n",
    "                print(f\"Warning: File {img_path} not found. Skipping this entry.\")\n",
    "                self.data = self.data.drop(_)\n",
    "\n",
    "        # -- Automatically handle string labels if they exist (e.g., \"car\", \"tank\")\n",
    "        if isinstance(self.data.iloc[0, 1], str):\n",
    "            classes = sorted(self.data.iloc[:, 1].unique())\n",
    "            self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}\n",
    "        else:\n",
    "            self.class_to_idx = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # -- around 3400 images now upgraded to 6k lol after adding more tanks  and after i lost my data i upgraded to 12k\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if th.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir, self.data.iloc[index, 0])  # csv file\n",
    "\n",
    "        # Read image with skimage.io\n",
    "        try:\n",
    "            image = io.imread(img_name)\n",
    "        except FileNotFoundError:\n",
    "            # -- erase entry if the data is missing\n",
    "            raise FileNotFoundError(f\"Missing file: {img_name}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error reading {img_name}: {e}\")\n",
    "\n",
    "        label_value = self.data.iloc[index, 1]\n",
    "        if self.class_to_idx:\n",
    "            #  -- map string label to index\n",
    "            label = th.tensor(self.class_to_idx[label_value], dtype=th.long)\n",
    "        else:\n",
    "            label = th.tensor(int(label_value), dtype=th.long)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21e453c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV  True\n",
      "Training folder True\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\#NAME? not found. Skipping this entry.\n",
      "Warning: File train\\grodno-belarus-july-25-2020-infantry-combat-vehicle-rides-dirt-road-along-field-against-background-forest-with-soldiers-board-various-military-equipment-exercises_678914-3335-1-_jpg.rf.99f5a3194a8f8e81412700e7206c2c14.jpg not found. Skipping this entry.\n",
      "Warning: File train\\different-military-vehicles-vector-illustrations-set-collection-drawings-armored-cars-trucks-tanks-humvee-armed-forces-white-background-war-army-transportation-technology-concept_74855-25972_jpg.rf.33fc4df753615e34a30f47258cf3d4ef.jpg not found. Skipping this entry.\n",
      "Warning: File train\\grodno-belarus-july-25-2020-infantry-combat-vehicle-rides-dirt-road-along-field-against-background-forest-with-soldiers-board-various-military-equipment-exercises_678914-3335-7-_jpg.rf.16e0a08dfba615b90a173ed7d3d0b03f.jpg not found. Skipping this entry.\n",
      "Warning: File train\\3d-realistic-military-tank-battle-tank-natural-colors-realistic-3d-design-military-vector-tanks-image-design-set-different-variations-your-design-illustration-needs_104045-3082-1-_jpg.rf.99503d8c54643b185eed68ee832f5437.jpg not found. Skipping this entry.\n",
      "Warning: File train\\3d-realistic-military-tank-battle-tank-natural-colors-realistic-3d-design-military-vector-tanks-image-design-set-different-variations-your-design-illustration-needs_104045-3082_jpg.rf.9bc5fe0b209166e24e4f5bcdb3c2a62a.jpg not found. Skipping this entry.\n",
      "Warning: File train\\different-military-vehicles-vector-illustrations-set-collection-drawings-armored-cars-trucks-tanks-humvee-armed-forces-white-background-war-army-transportation-technology-concept_74855-25972-1-_jpg.rf.27dc21db611631d48e60ce42ccc05417.jpg not found. Skipping this entry.\n",
      "Warning: File train\\0_jpg.rf.efee458b041692570bf50628b0625e92.jpg not found. Skipping this entry.\n",
      "Length of dataset: 12252\n",
      "Images in folder: 12246\n",
      " Valid image from both CSV file and the actual folder : 12216\n"
     ]
    }
   ],
   "source": [
    "# -- Checking if files are actually there -- i wanna know the bach size too == also importing it\n",
    "print(\"CSV \", os.path.exists(\"Cars_Tanks.csv\"))\n",
    "print(\"Training folder\", os.path.exists(\"train\"))\n",
    "\n",
    "dataset = CustomDatasetCarsANDTanks(\n",
    "    csv_file=\"Cars_Tanks.csv\",\n",
    "    root_dir=\"train\",\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    ")\n",
    "df = pd.read_csv(\"Cars_Tanks.csv\")\n",
    "print(\"Length of dataset:\", len(df))  # around 3348 images now with added tanks 6k lol now after i lost my data i upgraded to 12k\n",
    "\n",
    "\n",
    "# -- now trying to see the images in the files and comparing them against the csv entries to get the actual number of valid images\n",
    "\n",
    "image_extensions = {'.jpg', '.jpeg', '.png', '.gif'}\n",
    "folder_path = \"train\" # path to the folder containing images\n",
    "\n",
    "image_files = [\n",
    "    f for f in os.listdir(folder_path)\n",
    "    if os.path.splitext(f)[1].lower() in image_extensions   # -- checking for valid image extensions\n",
    "]\n",
    "\n",
    "print(\"Images in folder:\", len(image_files))   # -- number of images in the folder\n",
    "\n",
    "\n",
    "valid_extensions = {'.jpg', '.jpeg', '.png', '.gif'}   # for the intersection check\n",
    "\n",
    "csv_files = set(df.iloc[:, 0].astype(str))    # -- getting the file names as strings from the csv file\n",
    "folder_files = set(\n",
    "    f for f in os.listdir(folder_path)\n",
    "    if os.path.splitext(f)[1].lower() in valid_extensions   # same concept as above\n",
    ")\n",
    "\n",
    "\n",
    "matched_files = csv_files.intersection(folder_files)   # -- getting the common files in both csv and folder\n",
    "\n",
    "print(\" Valid image from both CSV file and the actual folder :\", len(matched_files))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61b4239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Creating a dataset loader --\n",
    "\n",
    "# -- dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)-- (dont even need it)\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [8551, 1222, 2443])  # -- 70/10/20 split\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)   # -- pin memeory to boos time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "717b01ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training batches: 268\n",
      "Number of validation batches: 77\n",
      "Number of testing batches: 77\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training batches:\", len(train_loader))\n",
    "print(\"Number of validation batches:\", len(val_loader))\n",
    "print(\"Number of testing batches:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fad44021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A batch shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# -- to check the shape, tho i am already confident <@:)\n",
    "print(f\"A batch shape: {train_loader.dataset[0][0].shape}\")  \n",
    "\n",
    "# --here 3 represents the colors which is RGB and 224,224 is the image size after resizing nice:)---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2785a98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNeuralNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=200704, out_features=512, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- Defining the CNN Model --\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")   # -- added this line to specify device --\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "OLD MODEL IGNORE\n",
    "\n",
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)  \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # 2 output classes: car and tank\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 56 * 56)  # -- basically we are flattening it here --\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\"\"\" \n",
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1) \n",
    "        self.bn1 = nn.BatchNorm2d(16)                                                              # -- added batch normalization -- since we are going to add more conv layers- padding to maintain size\n",
    "\n",
    "        # no pooling\n",
    "    \n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)  \n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)          # 1st pooling layer\n",
    "    \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # no pooling\n",
    "\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)         # 2nd pooling layer\n",
    "\n",
    "        \n",
    "    \n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)         # 3rd pooling layer\n",
    "\n",
    "        #--- Fully connected layers ---\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(256 * 28 * 28, 512)                        # first fully connected layer\n",
    "        self.dropout1 = nn.Dropout(0.5)                                 # for stabilization\n",
    "        self.fc2 = nn.Linear(512, 2)                                    # second fully connected layer for 2 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))           # relu to skip linearities\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)   # -- flattening -- safer than view\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# -- currently i have 2 conv layers, 2 pooling layers and 2 fully connected layers -- planning to add more... 25/10/2025 so added more conv layers specifically 5 conv layers and 3 pooling layers now still 25/10/2025 :) fast doer\n",
    "\n",
    "\n",
    "\n",
    "net = ConvNeuralNet()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c496465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 224, 224]             448\n",
      "       BatchNorm2d-2         [-1, 16, 224, 224]              32\n",
      "            Conv2d-3         [-1, 32, 224, 224]           4,640\n",
      "       BatchNorm2d-4         [-1, 32, 224, 224]              64\n",
      "         MaxPool2d-5         [-1, 32, 112, 112]               0\n",
      "            Conv2d-6         [-1, 64, 112, 112]          18,496\n",
      "       BatchNorm2d-7         [-1, 64, 112, 112]             128\n",
      "            Conv2d-8        [-1, 128, 112, 112]          73,856\n",
      "       BatchNorm2d-9        [-1, 128, 112, 112]             256\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "        MaxPool2d-13          [-1, 256, 28, 28]               0\n",
      "           Linear-14                  [-1, 512]     102,760,960\n",
      "          Dropout-15                  [-1, 512]               0\n",
      "           Linear-16                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 103,155,586\n",
      "Trainable params: 103,155,586\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 93.41\n",
      "Params size (MB): 393.51\n",
      "Estimated Total Size (MB): 487.50\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (3, 224, 224))  # i mean the input size is (3, 224, 224 as seen from module 7\n",
    "\n",
    "# from the code below we can see that the output shape becomes half after each pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30bd8675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/19:  37%|███▋      | 100/268 [00:48<01:24,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 13.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/19:  75%|███████▍  | 200/268 [01:44<00:40,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 200] loss: 0.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/19: 100%|██████████| 268/268 [02:21<00:00,  1.89it/s]\n",
      "Epoch 2/19:  37%|███▋      | 100/268 [00:54<01:26,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 100] loss: 0.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/19:  75%|███████▍  | 200/268 [01:53<00:37,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 200] loss: 0.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/19: 100%|██████████| 268/268 [02:30<00:00,  1.78it/s]\n",
      "Epoch 3/19:  37%|███▋      | 100/268 [00:55<01:42,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 100] loss: 0.450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/19:  75%|███████▍  | 200/268 [01:52<00:38,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 200] loss: 0.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/19: 100%|██████████| 268/268 [02:31<00:00,  1.77it/s]\n",
      "Epoch 4/19:  37%|███▋      | 100/268 [00:55<01:33,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 100] loss: 0.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/19:  75%|███████▍  | 200/268 [01:51<00:35,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 200] loss: 0.408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/19: 100%|██████████| 268/268 [02:30<00:00,  1.78it/s]\n",
      "Epoch 5/19:  37%|███▋      | 100/268 [00:56<01:33,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 100] loss: 0.389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/19:  75%|███████▍  | 200/268 [01:51<00:38,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 200] loss: 0.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/19: 100%|██████████| 268/268 [02:30<00:00,  1.79it/s]\n",
      "Epoch 6/19:  37%|███▋      | 100/268 [00:56<01:40,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 100] loss: 0.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/19:  75%|███████▍  | 200/268 [01:52<00:35,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 200] loss: 0.366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/19: 100%|██████████| 268/268 [02:30<00:00,  1.78it/s]\n",
      "Epoch 7/19:  37%|███▋      | 100/268 [00:58<01:46,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 100] loss: 0.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/19:  75%|███████▍  | 200/268 [02:04<00:41,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 200] loss: 0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/19: 100%|██████████| 268/268 [02:46<00:00,  1.61it/s]\n",
      "Epoch 8/19:  37%|███▋      | 100/268 [01:03<01:43,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 100] loss: 0.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/19:  75%|███████▍  | 200/268 [02:02<00:39,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 200] loss: 0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/19: 100%|██████████| 268/268 [02:39<00:00,  1.68it/s]\n",
      "Epoch 9/19:  37%|███▋      | 100/268 [00:57<01:32,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 100] loss: 0.366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/19:  75%|███████▍  | 200/268 [01:53<00:36,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 200] loss: 0.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/19: 100%|██████████| 268/268 [02:31<00:00,  1.77it/s]\n",
      "Epoch 10/19:  37%|███▋      | 100/268 [00:56<01:44,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 100] loss: 0.398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/19:  75%|███████▍  | 200/268 [01:42<00:31,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 200] loss: 0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/19: 100%|██████████| 268/268 [02:14<00:00,  1.99it/s]\n",
      "Epoch 11/19:  37%|███▋      | 100/268 [00:45<01:24,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 100] loss: 0.350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/19:  75%|███████▍  | 200/268 [01:33<00:28,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 200] loss: 0.337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/19: 100%|██████████| 268/268 [02:05<00:00,  2.14it/s]\n",
      "Epoch 12/19:  37%|███▋      | 100/268 [00:50<01:35,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 100] loss: 0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/19:  75%|███████▍  | 200/268 [01:45<00:36,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 200] loss: 0.338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/19: 100%|██████████| 268/268 [02:23<00:00,  1.87it/s]\n",
      "Epoch 13/19:  37%|███▋      | 100/268 [00:55<01:36,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 100] loss: 0.332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/19:  75%|███████▍  | 200/268 [01:51<00:35,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 200] loss: 0.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/19: 100%|██████████| 268/268 [02:29<00:00,  1.79it/s]\n",
      "Epoch 14/19:  37%|███▋      | 100/268 [00:56<01:44,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 100] loss: 0.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/19:  75%|███████▍  | 200/268 [01:50<00:34,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 200] loss: 0.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/19: 100%|██████████| 268/268 [02:21<00:00,  1.89it/s]\n",
      "Epoch 15/19:  37%|███▋      | 100/268 [00:47<01:24,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 100] loss: 0.337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/19:  75%|███████▍  | 200/268 [01:34<00:28,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 200] loss: 0.331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/19: 100%|██████████| 268/268 [02:05<00:00,  2.13it/s]\n",
      "Epoch 16/19:  37%|███▋      | 100/268 [00:47<01:12,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 100] loss: 0.310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/19:  75%|███████▍  | 200/268 [01:34<00:34,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 200] loss: 0.319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/19: 100%|██████████| 268/268 [02:05<00:00,  2.14it/s]\n",
      "Epoch 17/19:  37%|███▋      | 100/268 [00:47<01:24,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 100] loss: 0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/19:  75%|███████▍  | 200/268 [01:33<00:32,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 200] loss: 0.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/19: 100%|██████████| 268/268 [02:04<00:00,  2.15it/s]\n",
      "Epoch 18/19:  37%|███▋      | 100/268 [00:47<01:20,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 100] loss: 0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/19:  75%|███████▍  | 200/268 [01:34<00:30,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 200] loss: 0.290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/19: 100%|██████████| 268/268 [02:05<00:00,  2.13it/s]\n",
      "Epoch 19/19:  37%|███▋      | 100/268 [00:46<01:18,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 100] loss: 0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/19:  75%|███████▍  | 200/268 [01:34<00:29,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 200] loss: 0.277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/19: 100%|██████████| 268/268 [02:05<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy of the model on the validation images: 91.20%\n"
     ]
    }
   ],
   "source": [
    "# -- now training the model --\n",
    "\n",
    "import torch.optim as optim # -- since we did not import it earlier --\n",
    "from torch.optim.lr_scheduler import StepLR  #-- for learning rate scheduler --\n",
    "\n",
    "from tqdm import tqdm   # -- for progress bar --\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay= 1e-4)  #-- 0.001 was my initial learning rate but i increased it to 0.42 nvm get it back to 0.001 -- weight decay for regularization\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)  # -- learning rate scheduler to reduce LR every 5 epochs by a factor of 0.5\n",
    "# loss = criterion(outputs, labels) # adding this later \n",
    "\n",
    "\n",
    "\n",
    "# -- an error is comming up in my CSV files ofc man i didntt clean them properly -- lets fix it \n",
    "# all the fixes are above in the dataset class ( importing dataset class module specifically )\n",
    "\n",
    "\n",
    "# -- after i added more tanks then another error came up -- lets fix it\n",
    "# basically the files are missing but are still in the CSV so i guess i will again tinker with the dataset class to see what i can do man this is getting annoying\n",
    "\n",
    "\n",
    "epchos = 19\n",
    "for epoch in range(epchos):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epchos}\"), 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 100 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}\") # -- printing average loss over last 100 batches --\n",
    "            running_loss = 0.0\n",
    "\n",
    "    \n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Validation Accuracy of the model on the validation images: {accuracy:.2f}%') \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a54609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporrary code to check device placement\n",
    "# -- i decided to keep it here but might delete it because why not :) its practically useless\n",
    "\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Current device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
    "net = ConvNeuralNet().to(device)\n",
    "print(next(net.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05c92b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test images: 91.49%\n",
      "                                            filename  car\n",
      "0  images266-2-_jpg.rf.b8ca42a696e0fab22f27517786...    0\n",
      "1  images24-77-_png.rf.f493a48626486b306292bbaeb8...    0\n",
      "2  images264-1-_jpg.rf.a4e7bc2fbf5604e0ef0a2e4c65...    0\n",
      "3  102-133-_jpg.rf.cf3600113eb6c148c1b8ed1465b419...    0\n",
      "4  106-237-_jpg.rf.65a5efd274c43e4b1669b01db774ec...    0\n",
      "\n",
      "Names ['filename', 'car']\n",
      "car\n",
      "1    6161\n",
      "0    6091\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():                    \n",
    "    for data in test_loader:\n",
    "        images, labels = data                #-- getting images and labels from the test loader --\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()              #-- calculating correct predictions --\n",
    "\n",
    "print(f\"Accuracy on the test images: {100 * correct / total:.2f}%\")\n",
    "\n",
    "\n",
    "csv_path = r\"C:\\Users\\Mudassar\\Desktop\\Z_Image\\Cars_Tanks.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(df.head())\n",
    "print(\"\\nNames\", df.columns.tolist())          #-- checking the dataset\n",
    "print(df['car'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1663c9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True test accuracy: 90.99%\n"
     ]
    }
   ],
   "source": [
    "# -- checking if the accuracy is the same as before -- 3rd check i am a skeptical person :O\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [0.7, 0.15, 0.15], generator=generator)\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"True test accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6b405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the full mode\n",
    "\n",
    "torch.save(net.state_dict(), \"car_tank_cnn_model_v2_MAIN.pth\")\n",
    "print(\"Model saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
